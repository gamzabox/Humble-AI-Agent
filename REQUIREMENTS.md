# 요구 사항

## 1. 핵심 워크플로
### 1.1 채팅 흐름
- 애플리케이션은 Flutter 구현된 데스크톱 챗 클라이언트를 제공해야 한다.
- 사용자는 입력창에 메시지를 작성하고 `Send` 버튼으로 전송할 수 있어야 하며, 전송 즉시 해당 질문은 파란색 말풍선으로 대화 영역 우측에 표시되어야 한다.
- 메시지를 전송하면 입력창은 비활성화되고 `Send` 버튼이 `Cancel`로 바뀌어 진행 중인 요청을 취소할 수 있어야 한다.
- 요청이 처리되는 동안 어시스턴트 영역에는 “Waiting Response”가 자리 표시자로 나타나야 하며, 모델이 반환하는 토큰을 스트리밍으로 수신해 자리 표시자를 즉시 대체해야 한다.
- 요청이 성공적으로 종료되면 자리 표시자는 완성된 응답으로 치환되고 입력창은 다시 활성화되어야 한다.
- 취소가 발생하면 어시스턴트 메시지는 기록되지 않아야 하고, 입력창·버튼 상태는 초기 전송 이전과 동일하게 복원되어야 한다.
- 오류가 발생하면 오류 메시지를 입력 영역 아래에 표시하고, 사용자가 다시 전송할 수 있도록 입력창을 초기화해야 한다.
- 길이가 긴 응답을 수신할 때는 최신 내용이 바로 보이도록 스크롤을 자동으로 하단으로 이동해야 한다.
- Shift+Enter 키로 메시지를 전송한다. Enter만 누르면 입력창에 줄바꿈을 삽입한다.
- 전송 중에는 입력창이 비활성화되고 버튼이 Cancel로 바뀐다. New Chat을 클릭하면 우선 취소 후 새 세션을 생성한다.

### 1.2 세션/히스토리 관리
- 앱은 항상 새로운 세션으로 시작하지만, 좌측 세션 목록에서 기존 세션을 즉시 선택해 내용을 열람할 수 있어야 한다.
- “새 새션” 버튼을 누르면 현재 진행 중인 응답을 정리하고 빈 세션이 활성화되어야 한다.
- 실제 메시지가 추가되기 전까지는 새 세션을 저장하지 않아야 하며, 빈 세션이 저장 파일에 남지 않아야 한다.
- 세션 제목은 첫 번째 사용자 메시지를 기반으로 하며, 메시지가 없을 경우 `"New Chat"`으로 표시해야 한다.
- 좌측 목록에서 세션을 선택하면 우측 대화 영역이 해당 세션 내용으로 교체되고, 선택된 항목은 굵은 글씨로 표시되어야 한다.
- 세션과 모델 설정은 각각 JSON 파일로 저장되어 다음 실행 시에도 복원되어야 한다. 저장 경로는 `~/.config/humble-ai-agent/` 디렉터리여야 하며, 필요한 디렉터리가 없으면 생성해야 한다.
- 좌측 세션 목록에서 선택된 항목은 굵게 표시한다. 각 세션 항목에 삭제 버튼을 제공하며, 현재 세션이 삭제되면 최근 세션을 자동으로 선택한다.
- 방금 전송하는 요청에서는 UI 플레이스홀더(Waiting Response…)는 API 메시지에 포함하지 않는다. API에는 이전 user/assistant 교환과 새 user 질문만 포함한다.

## 2. 모델 관리 및 설정
- 모델 선택 드롭다운에는 등록된 모델이 `모델명 (제공자)` 형식으로 나열되어야 하고, 선택 변경 시 즉시 적용되어야 한다.
- 드롭다운 우측의 톱니바퀴 버튼을 누르면 설정 다이얼로그가 열려 모델 추가·수정·삭제를 수행할 수 있어야 한다.
- 모델 설정은 `config.json` 파일로 저장되며, 추가/수정 시 제공자에 맞는 필수 입력 값에 따라 저장 가능 여부를 판단해야 한다.
  - OpenAI: `Model`, `API Key`가 필수이며 `Base URL` 입력은 비활성화해야 한다.
  - Ollama: `Model`, `Base URL`이 필수이며 `API Key` 입력은 비활성화해야 한다.
- 모델을 추가하면 현재 선택된 모델이 자동으로 해당 모델로 변경되어야 한다.
- 설정 다이얼로그에는 About 섹션이 포함되어 “Humble AI Agent”, 현재 버전, 개발자 “gamzabox”를 표시해야 한다.

## 3. UI 및 표현 요구사항
### 3.1 레이아웃
- 기본 레이아웃은 좌측에 세션 목록, 우측에 대화 영역과 입력 영역을 둔 수평 분할 구조여야 한다.
- 초기 분할 비는 좌측 30%, 우측 70% 정도가 되어야 하며 사용자가 자유롭게 조절할 수 있어야 한다.
- 대화 영역은 질문과 답변이 세로로 순차 표시되는 형태이며, 사용자 질문 말풍선은 우측 정렬·밝은 텍스트 색상으로 표시되어야 한다.
- AppBar 없이도 우측 영역 상단에 컨트롤 바를 두고, 모델 선택 드롭다운과 설정 버튼을 배치한다.
- 모든 플랫폼에서 macOS 스타일 테마를 적용하되, 기본 분할 비(좌 30% / 우 70%)는 유지한다.

### 3.2 Markdown 렌더링
- 어시스턴트 응답은 Markdown을 Html 로 변환해 Webview 를 이용해 출력 해야 한다.
- 중첩 목록은 깊이에 따라 들여쓰기 수준이 유지되어야 한다.
- 코드 블록은 GitHub 테마와 유사한 배경색과 구문 하이라이팅을 적용해야 한다.
- 응답은 카드 형태로 사용자 말풍선 아래에 표시되며, 이후 응답이 갱신될 때마다 스트리밍으로 변경 사항을 반영해야 한다.
- Assistant 답변은 말풍선 없이 본문으로 렌더링한다. User/상태 메시지만 말풍선 형태를 사용한다.
- 코드 블록은 GitHub 테마로 구문 하이라이트하고, 펜스드 코드블록의 언어 힌트를 반영한다(예: ```dart).
- 대화 화면 전체는 드래그 선택/복사가 가능해야 하며, 코드 블록도 SelectableText 기반으로 선택/복사가 가능해야 한다.

### 3.3 오류 및 상태 표시
- 진행 중인 상태, 취소, 오류 등의 변화는 입력 영역 아래의 상태 메시지 또는 UI 상태 변화를 통해 즉시 안내해야 한다.
- 빈 입력을 전송하려고 하면 동작하지 않아야 하며 UI 변동도 없어야 한다.
- 네트워크/권한 오류 시 입력 영역 상단에 에러 배너를 띄우고 Retry 버튼으로 마지막 프롬프트를 재시도할 수 있어야 한다.

## 4. 저장 및 데이터 처리
- 세션 데이터는 `sessions.json` 파일에 저장해야 하며, 각 레코드는 고유 ID, 제목, 메시지 목록을 포함해야 한다.
- 저장 시 파일이 없으면 새로 생성하고, 쓰기 전 임시 파일 방식으로 안전하게 저장해야 한다.
- 세션별 메시지는 유저·어시스턴트 역할, 내용이 모두 보존되어야 하며, 중간 응답 자리표시자는 저장하지 않아야 한다.
- 모델 설정과 세션 저장 로직은 각각 독립적으로 동작해야 하며, 저장 실패 시 애플리케이션이 중단되지 않도록 처리해야 한다.

## 5. 스트리밍 및 네트워크
- OpenAI 및 Ollama와의 대화 요청은 스트리밍 API를 사용하여 토큰 단위의 응답을 받아야 한다.
- OpenAI의 경우 SSE 기반 응답을 파싱하고, Ollama는 JSON 라인 기반 스트림을 읽어야 한다.
- 스트리밍 중에는 부분 응답을 UI에 반영하고, 최종 응답이 완료되면 전체 메시지를 저장해야 한다.
- 네트워크 호출은 취소 가능한 컨텍스트를 사용해 사용자가 `Cancel`을 눌렀을 때 즉시 중단될 수 있어야 한다.

## 6. 비기능 요구사항
- 네트워크 클라이언트는 인터페이스로 추상화돼 테스트 시 모킹이 가능해야 한다.
- UI 업데이트는 안전하게 실행돼야 하며, 장시간 스트리밍 중에도 응답성이 유지돼야 한다.
- 핵심 동작(모델 선택, 메시지 전송, 저장/로드, 취소 등)은 자동화된 테스트로 검증해야 한다.
- 저장 파일과 디렉터리 생성은 권한 오류 등을 감안해 우아하게 처리해야 한다.

## 7. 범위 및 가정
- 지원 모델은 OpenAI와 Ollama에서 제공하는 텍스트 기반 챗/완성 모델로 한정한다.
- 다국어 UI 지원, 음성/이미지 입력, 첨부 파일, 팀 협업 기능 등은 초기 범위에서 제외한다.
- 인터넷 연결이 가능하고 로컬 디스크에 설정·세션 파일을 저장할 수 있는 환경을 가정한다.

## 8. 추가 요구사항
- 세션 목록에서 선택 항목 굵게 표시 + 각 세션 삭제 버튼 제공. 삭제 시 현재 세션이 제거되면 최신 세션 자동 선택.
- Markdown 코드 블록은 GitHub 테마로 하이라이트하며, 펜스드 코드블록(예: ```dart)의 언어 힌트를 반영해 해당 언어로 구문 강조 적용.
- 네트워크/권한 오류 발생 시 입력 영역 상단에 에러 배너 표시 및 Retry 버튼으로 마지막 프롬프트 재시도

